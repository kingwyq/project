mapreduce是分布式计算编程模型，该模型分为两个阶段：map阶段和reduce阶段，map阶段处理map task，reduce阶段处理reduce task。
(1)多个机器上的map task并行处理各自的数据block，产生各自的结果。
(2)每个map task完成后将结果交给reduce task进行结果汇总，不同的任务reduce task需要处理的对应map task的结果是不同的。
此时会产生如下问题：
(1)map task数据块分配
(2)reduce task任务分配
(3)map task产生的结果该交给哪个reduce task处理
(4)当其中一个map task没有执行成功，此时该怎么办。
为了解决对应的问题，需要有一个主管来协调，此主管在map reduce编程模型中叫做application master
application master主要负责为启动map task,为map task分配需要处理的数据块，对于各机器上map task执行后产生的结果该交给哪个reduce task处理，由application
master负责分配，对于某些map task执行不成功的情况，由application master负责监控，一但发生，application master会在其他机器上启动map task处理对应数据块。

mapreduce 应用
mapreduce编程需要实现mapper和reducer接口，完成代码逻辑
mapper层主要实现将给定文本中的内容按行读取，以key,value的形式传给用户重写的方法，其中key是偏移量，value是读取的一行文本的内容，这里key，value的类型是
hadoop中的序列化类型，按照业务类型实现逻辑后，将输出同样以key，value的形式表示。输出首先写入到context对象中，根据需要，mapper输出分区可以分为多个，默认情况
下分区最多三个，是由默认的hashPartioner方法决定的，因此如果要自定义分区的数量需要重新实现partioner接口，新的方式是extends partioner，只需要重写其中的
getPartioner方法，该方法返回整数，即分区号。
reducer层接收key，value，输出key，value，接收到的key，value，是mapper层的输出，mapper层可以将不同输出分区的内容交给不同的reducer，reducer接收到的
key不重复（可以这样理解），value是一个Iteratorable，输出的value可以是自定义对象（根据业务需求而定）,当然当定义为自定义输出对象时，应该重写toString方法
，这样可以保证最后的输出是以文本的方式。同时还应该让自定义对象实现hadoop的序列化接口，Writable（对象需要序列化后在进行传输，在接收端反序列化）。reducer
task默认情况下只启动一个，此时因该通过设置job对象的参数根据业务要求自定义数量（更改reducer task的数量一般要指定mapper输出分区划分的实现类）。
mapreduce总的main方法主要完成任务分配，任务提交。
主要给yarn提交数据切片信息，job.xml，jar包，数据切片数量决定map task的数量，job.xml是任务执行的一些参数设置，jar包主要包含是用户任务逻辑实现。

mapreduce的工作流程
首先是采用FileInputformat的实现类完成输入数据的切片，默认采用的实现类是TextInputformat,可以自己实现FileInputformat，实现Recoredreader类，重写其中的
read方法，close方法。其中的切片方法决定map task的数目，read方法可以决定传给map方法的key，value。map方法中完成处理，采用context写出去，这时是将其序列化
写入环形缓冲区中(因此这里的key和value只需要new一个，通过修改其中的值即可)，环形缓冲区可以配置什么时候溢出，溢出后写入对应的分区，分区的划分是通过实现
Partioner，重写其中的getPartioner方法，默认的partioner实现类是HashPartioner，此时，分区个数由reducer的数目决定，但是其他自定义的可以不取决于reducer的
数目，溢出的内容进入不同的分区，并且采用快速排序完成分区且有序，这里的有序是指按照key的顺序，因此，如果key采用自定义的bean，则此bean需要实现writableComparable
le，仅实现writable是具备序列化功能，实现WritableComparable则既具备序列化功能，又具备比较功能。同一个分区的内容进入同一个reducer处理，因此到达reducer端
不同map的同一分区内容需要合并，此时是多个有序序列合并为一个有序序列，采用归并排序实现，最后，经过reducer处理后输出到文件中，输出到文件是通过Fileoutformat
的实现类完成的，也可以自定义其实现那类，默认的是Textoutputformat，自定义还需要实现recordwriter，通过其中的write方法采用相应的流写入文件中，这里的output
format在map端也可以用到，在有些情况下，并不需要reducer，此时，map处理完就可以直接输出到文件中。最后，讨论一下，combiner的使用，combiner的使用应该保证最终
的结果不会错，combiner就是在map溢出输出到分区时进行合并，这样可以减少传输以及reducer的处理数量。
yarn的工作原理
yarn和mapreducer程序是完全解耦的，程序通过发送相应的启动指令，将任务放入resource manager的任务队列之中，resource manager将任务交给相应的node manager
处理，这是基本的原理，对于MapReduce程序需要先启动mrapp master，然后mrapp master负责将任务交给resource manager，任务是map task，和reduce task执行
任务。
